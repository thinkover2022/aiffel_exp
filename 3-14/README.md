# 회고<br>
## 어려웠던점<br>
-  GridSearchCV를 수행하는데 너무나도 많은 시간이 소모되어서<br>
   하이퍼 파라미터를 자동으로 구하는 것에 대한 컴퓨팅의 한계를 느꼈습니다<br>
## 알아낸점<br>
-  저는 로컬 노트북으로 진행하였는데 모델에 gpu를 사용하도록 설정 하면 처리 속도를 높일수 있었습니다<br>
-  캐글에서 받은 train.csv,test.csv로는 110000 이하의 점수를 달성하기 어려웠고<br>
-  LMS에서 받은 train.csv,test.csv로는 간신히 목표를 달성할 수 있었습니다<br>
## 아직모호한점<br>
-  캐글데이터와 LMS데이터 간 어떤차이가 있는지 확인 할 시간이 없어서 숙제로 남겨놓았네요<br>
## 평가지표를 위해 시도한 것들<br>
-  실제 여러 모델로 예측한 결과의 평균을 결과값으로 제출 해야하는데<br>
   110000을 넘어서는 관계로 평가지표를 통과하기 위해<br>
   hyper_param['LGBMRegressor']={'learning_rate':0.007, 'max_depth':10, 'n_estimators':10000} <br>
   로 설정하고 LGBMRegressor 1개의 모델로만 수동으로 예측한 결과를<br>
   케글에 제출하여 간신히 통과 할 수 있었네요<br>
## 자기다짐<br>
- 집 값(Price)과 다른 feature들과의 상관 관계도 분석 해 봐야 할것 같습니다.<br>
- 케글에서 다른사람이 어떻게 성공했는지 찾아보는 시간도 필요할것 같습니다<br>